# Algorithmic Decision-Making and the Rule of Law

Check out [this Q&A](http://www.allard.ubc.ca/news-events/ubc-law-news/bridging-gap-between-law-and-technology) for more information about this semi-regular, interdisciplinary reading group.

Join the UBC-hosted mailing list by emailing listserv@lists.ubc.ca with the words
“subscribe UBC-ALGORITHMS-RULE-OF-LAW” in the body.

And please share your suggestions for this bibliography and/or future sessions by [opening an issue](https://github.com/sanchom/algorithmic-decision-making-and-rule-of-law/issues) or just email sanchom@gmail.com.

Thanks to Peter A. Allard School of Law and Professor Cristie Ford for supporting this group.

## Sessions

### March 24, 2021

- Kathleen Creel & Deborah Hellman, \"The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision Making Systems\" (2021) ACM Conference on Fairness, Accountability, and Transparency, online: \<[papers.ssrn.com/sol3/papers.cfm?abstract_id=3786377](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3786377)\>.

### November 24, 2020

- Ryan Calo & Danielle Keats Citron, \"The Automated Administrative State: A Crisis of Legitimacy\", Emory Law Journal \[forthcoming in 2020\], online: \<[papers.ssrn.com/sol3/papers.cfm?abstract_id=3553590](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3553590)\>.

### August 6, 2020

- Nenad Tomašev et al, \"AI for Social Good: Unlocking the Opportunity for Positive Impact\", (18 May 2020) 11 Nature Communications, online: \<[doi.org/10.1038/s41467-020-15871-z](https://doi.org/10.1038/s41467-020-15871-z)\>. (With guest discussion leads: Nenad Tomašev and Shakir Mohamed, two of this paper's co-authors.)

### March 31, 2020

-   Sandra Wachter, Brent Mittelstadt & Chris Russell,
    "[Counterfactual
    Explanations without Opening the Black Box: Automated Decisions and
    the GDPR](https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf)" (2018) 31:2 Harvard J Law & Tech 841.

### February 6, 2020

-  Discussion of Anya Prince & Daniel Schwarcz,
    "[Proxy
    Discrimination in the Age of Artificial Intelligence and Big
    Data](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3347959)" (forthcoming in 2020) Iowa LR.

### November 21, 2019

-  Introductory session. Discussed general terminology, assumptions, and goals of algorithmic/AI decision-making. Discussion was based around Hildebrandt's Chapter 2, Wachter, Mittelstadt & Russell's "Counterfactual Explanations", Molnar and Gil's *Bots at the Gate*, and the Treasury Board's *Directive on Automated Decision-Making*.

## Bibliography

### Theory

-   Mireille Hildebrandt, [*Law for Computer
    Scientists*](https://lawforcomputerscientists.pubpub.org/) (Oxford
    University Press, 2019).
-   Anya Prince & Daniel Schwarcz,
    "[Proxy
    Discrimination in the Age of Artificial Intelligence and Big
    Data](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3347959)" (forthcoming in 2020) Iowa LR.
-   John Zerilli et al, \"[Algorithmic Decision-Making and the Control
    Problem](https://link.springer.com/article/10.1007/s11023-019-09513-7)\" (2019)
    29:4 Minds & Machines 555.
-   Karen Yeung & Margin Lodge, eds, [*Algorithmic
    Regulation*](https://www.oxfordscholarship.com/view/10.1093/oso/9780198838494.001.0001/oso-9780198838494-chapter-1)
    (Oxford University Press, 2019).
-   Mary Liston, \"Expanding the Parameters of Participatory Public Law:
    A Democratic Right to Public Participation and the State\'s Duty of
    Public Consultation\" (2017) 63:2 McGill LJ 375.
-   Ryan Calo & Danielle Keats Citron, \"The Automated Administrative State: A Crisis of Legitimacy\", Emory Law Journal \[forthcoming in 2020\], online: 
    \<[papers.ssrn.com/sol3/papers.cfm?abstract_id=3553590](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3553590)\>.

### Case studies / application evaluations

-   Petra Molnar & Lex Gill,
    [*Bots
    at the Gate: A Human Rights Analysis of Automated Decision-Making in
    Canada's Immigration and Refugee System*](https://citizenlab.ca/wp-content/uploads/2018/09/IHRP-Automated-Systems-Report-Web-V2.pdf) (Toronto: International
    Human Rights Program and Citizen Lab, 2018).
-   Andrea Roth, \"[Machine
    Testimony](https://www.yalelawjournal.org/article/machine-testimony)\" (2017)
    126:7 Yale LJ 1972.

### Industry and academic response / technical initiatives / standards creation

-   Nenad Tomašev et al, \"AI for Social Good: Unlocking the Opportunity for Positive Impact\", (18 May 2020) 11 Nature Communications, online: \<[doi.org/10.1038/s41467-020-15871-z](https://doi.org/10.1038/s41467-020-15871-z)\>.
-   Thoughtworks, \"Technology Radar (Vol 21)\" (20 November 2019),
    online:
    <assets.thoughtworks.com/assets/technology-radar-vol-21-en.pdf>.
-   University of Montréal,
    [*Montreal
    Declaration for a Responsible Development of Artificial
    Intellgence*](https://www.montrealdeclaration-responsibleai.com/the-declaration) (2017).
-   Amnesty International & Access Now, [*The Toronto Declaration:
    Protecting the Right to Equality in Machine
    Learning*](https://www.torontodeclaration.org) (2018).
-   Mowat Centre, \"[Governing the Future: Creating Standards for
    Artificial Intelligence and
    Algorithms](https://munkschool.utoronto.ca/mowatcentre/governing-the-future-creating-standards-for-artificial-intelligence-and-algorithms/)\"
    (3 June 2019).
-   Sandra Wachter, Brent Mittelstadt & Chris Russell,
    "[Counterfactual
    Explanations without Opening the Black Box: Automated Decisions and
    the GDPR](https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf)" (2018) 31:2 Harvard J Law & Tech 841.
-   Google Pair, \"What-If Tool\", online:
    \<pair-code.github.io/what-if-tool\>.
-   Google, \"Explainable AI\", online:
    \<[cloud.google.com/explainable-ai/](https://cloud.google.com/explainable-ai/)\>.
-   Cynthia Rudin & Joanna Radin, \"Why Are We Using Black Box Models in
    AI When We Don\'t Need To? A Lesson From An Explainable AI
    Competition\" (2019) 1:2 Harvard Data Science Review, DOI:
    \<[10.1162/99608f92.5a8a3a3d](https://doi.org/10.1162/99608f92.5a8a3a3d)\>.
-   Cynthia Rudin, \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\"
    (2019) 1 Nature Machine Intelligence 206, DOI: \<[10.1038/s42256-019-0048-x](https://doi.org/10.1038/s42256-019-0048-x)\>.
-   DARPA, \"Explainable AI Program Update\" (November 2017), online:
    \<[www.darpa.mil/attachments/XAIProgramUpdate.pdf](https://www.darpa.mil/attachments/XAIProgramUpdate.pdf)\>.
-   MIT, \"Computational Law Report\" (2019), online:
    \<[law.mit.edu](https://law.mit.edu/)\>.
-   Crawford et al, *AI Now 2019 Report* (New York: AI Now Institute, 2019), online: \<[ainowinstitute.org/AI_Now_2019_Report.html](ainowinstitute.org/AI_Now_2019_Report.html)\> (annual report from an institute focused on the social implications of AI technology; recommendations for government and industry relating to workers rights, privacy, decision-making, and accountability).
-   Harrison Edwards & Amos Storkey, "Censoring Representations with an Adversary" (2015) International Conference on Learning Representations, online: \<[arXiv/1511.05897](https://arxiv.org/abs/1511.05897)\>.

### Regulatory approaches and evaluation thereof

-   Canada, Treasury Board, *Directive on Automated Decision-Making*
    (Ottawa: Treasury Board, 2019), online:
    \<[www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592)\>.
-   EC, *Regulation (EU) 2016/679 of the European Parliament and of the
    Council of 27 April 2016* *on the protection of natural persons with
    regard to the processing of personal data* *and on the free movement
    of such data, and repealing* *Directive 95/46/EC* *(General Data
    Protection Regulation)* \[2016\] OJ, L 119/1, art 22.
-   Sandra Wachter, Brent Mittelstadt & Luciano Floridi, \"Why a Right
    to Explanation of Automated Decision-Making Does Not Exist in the
    General Data Protection Regulation\" (2017) 7:2 Intl Data Privacy
    Law 76, online:
    \<[academic.oup.com/idpl/article/7/2/76/3860948](https://academic.oup.com/idpl/article/7/2/76/3860948)\>.
-   Bryce Goodman & Seth Flaxman, \"[European Union Regulations on
    Algorithmic Decision-Making and a \'Right to
    Explanation\'](https://ora.ox.ac.uk/objects/uuid:593169ee-0457-4051-9337-e007064cf67c/download_file?safe_filename=euregs.pdf)\".
-   EC, Panel for the Future of Science and Technology, \"[Understanding
    Algorithmic Decision-Making: Opportunities and
    Challenges](https://www.europarl.europa.eu/RegData/etudes/STUD/2019/624261/EPRS_STU(2019)624261_EN.pdf)\"
    by Claude Castelluccia & Daniel Le MÃ©tayer (Brussels: March 2019).
-   EC, Panel for the Future of Science and Technology, \"[A Governance
    Framework for Algorithmic Accountability and
    Transparency](https://www.europarl.europa.eu/RegData/etudes/STUD/2019/624262/EPRS_STU(2019)624262_EN.pdf)\"
    by Ansgar Koene et al (Brussels: April 2019).
-   EC, "On Artificial Intelligence -A European approach to excellence and trust" (White Paper), online: \<[ec.europa.eu/info/files/white-paper-artificial-intelligence-european-approach-excellence-and-trust_en](https://ec.europa.eu/info/files/white-paper-artificial-intelligence-european-approach-excellence-and-trust_en)\>
-   Lorna McGregor, Daragh Murray & Vivian Ng, \"[International Human
    Rights Law as a Framework for Algorithmic
    Accountability](https://www.cambridge.org/core/journals/international-and-comparative-law-quarterly/article/international-human-rights-law-as-a-framework-for-algorithmic-accountability/1D6D0A456B36BA7512A6AFF17F16E9B6)\" (2019)
    68:2 Int\'l & Comparative LQ.
-   US, Executive Office of the President, [*Big Data: A Report on
    Algorithmic Systems, Opportunity, and Civil
    Rights*](https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf)
    (Washington, DC: US Government Printing Office, 2016).
-   UK, Royal Academy of Engineering, [*Algorithms in
    Decision-Making*](https://www.raeng.org.uk/publications/responses/algorithms-in-decision-making)
    (Response to House of Commons Science and Technology Committee
    Inquiry into the Use of Algorithmis in Decision-Making) (April
    2017).

### Judicial context

-   *Canada (Minister of Citizenship and Immigration) v Vavilov*, 2019
    SCC 65 (framework for judicial, substantive review of administrative action).
-   *Fraser v Canada (Attorney General)*, 2020 SCC 28 (disparate-impact / adverse-effects claims under s. 15 of the *Charter*)

### Other reading

-   Safiya Umoja Noble, *Algorithms of Oppression: How Search Engines
    Reinforce Racism* (New York: New York University Press, 2018).
-   Michael Kearns & Aaron Roth, *The Ethical Algorithm: The Science of Socially Aware Algorithm Design* (New York, Oxford University Press: 2019); *Ipse Dixit*, "Aaron Roth & Michael Kearns on Ethical Algorithms" (podcast) (2 March 2019), online: \<[shows.acast.com/ipse-dixit/episodes/aaron-roth-michael-kearns-on-ethical-algorithms](https://shows.acast.com/ipse-dixit/episodes/aaron-roth-michael-kearns-on-ethical-algorithms)\>.
